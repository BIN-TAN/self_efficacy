{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a7c5efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">results=0.468, best_score=0.463, best_param={'max_depth': 5, 'n_estimators': 150}\n",
      ">results=0.466, best_score=0.464, best_param={'max_depth': 5, 'n_estimators': 150}\n",
      ">results=0.465, best_score=0.464, best_param={'max_depth': 5, 'n_estimators': 150}\n",
      ">results=0.466, best_score=0.464, best_param={'max_depth': 5, 'n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#import data\n",
    "data = pd.read_csv(\"processed_data.csv\")\n",
    "\n",
    "#define target\n",
    "y = data[\"self_efficacy\"]\n",
    "y = y * 15 + 100\n",
    "data.drop(\"self_efficacy\", axis=1, inplace = True)\n",
    "\n",
    "#define features\n",
    "X = data.iloc[:, 1:]\n",
    "\n",
    "##############################################################################\n",
    "# configure the cross-validation procedure\n",
    "cv_outer = KFold(n_splits=4, shuffle=True, random_state=100)\n",
    "\n",
    "# enumerate splits\n",
    "outer_results = list()\n",
    "inner_results = list()\n",
    "\n",
    "r2_0 = 0\n",
    "\n",
    "for train_ix, test_ix in cv_outer.split(X):\n",
    "    X_train, X_test = X.iloc[train_ix, :], X.iloc[test_ix, :] \n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix] \n",
    "\n",
    "    cv_inner = KFold(n_splits=4, shuffle=True, random_state=100) \n",
    "    model = XGBRegressor(random_state=100) \n",
    "\n",
    "    space = dict() \n",
    "    space['max_depth'] = [5, 15, 20, 25] \n",
    "    space['n_estimators'] = [50, 100, 150] \n",
    "    \n",
    "    search = GridSearchCV(model, space, \n",
    "                          scoring = [\"r2\", \"neg_mean_squared_error\",\n",
    "                                     \"neg_mean_absolute_error\"], \n",
    "                          refit= \"r2\", cv=cv_inner,\n",
    "                          return_train_score=True,\n",
    "                          n_jobs = 9\n",
    "                          ) \n",
    "\n",
    "    results = search.fit(X_train, y_train) \n",
    "    best_model = results.best_estimator_ \n",
    "\n",
    "#get inner results:\n",
    "    inner_results.append(results.cv_results_)\n",
    "\n",
    "#outer evaluation and get the results\n",
    "    yhat = best_model.predict(X_test) \n",
    "    rmse = math.sqrt(mean_squared_error(y_test, yhat))\n",
    "    mae = mean_absolute_error(y_test, yhat) \n",
    "    r2 = r2_score(y_test, yhat)\n",
    "    outer_results.append([rmse, mae, r2]) \n",
    "    \n",
    "    if r2 > r2_0:\n",
    "       r2_0 = r2\n",
    "       importance = best_model.feature_importances_\n",
    "\n",
    "    print('>results=%.3f, best_score=%.3f, best_param=%s' % (r2, results.best_score_, results.best_params_))\n",
    "\n",
    "results_Df_outer = pd.DataFrame(outer_results)\n",
    "results_Df_outer.to_csv(\"resultsXGB_outer_1.csv\")\n",
    "\n",
    "results_Df_inner = pd.DataFrame(inner_results)\n",
    "results_Df_inner.to_csv(\"resultsXGB_inner_1.csv\")\n",
    "\n",
    "#get the feature importance\n",
    "feat_importances = pd.Series(importance, index = X_train.columns)\n",
    "DT_feature_importance = pd.DataFrame(feat_importances)\n",
    "DT_feature_importance.to_csv(\"XGB_feature_importance_1.csv\")\n",
    "\n",
    "mean_r2_test = list()\n",
    "mean_r2_train = list()\n",
    "mean_neg_MSE_train = list()\n",
    "mean_neg_MSE_test = list()\n",
    "mean_neg_mean_absolute_error_test = list()\n",
    "mean_neg_mean_absolute_error_train = list()\n",
    "\n",
    "for i in range(4):\n",
    "    inner_res = pd.DataFrame(inner_results[i])\n",
    "    max_r2_test = inner_res[[\"split0_test_r2\", \"split1_test_r2\", \"split2_test_r2\", \"split3_test_r2\"]].max()\n",
    "    mean_r2_test.append(np.mean(max_r2_test))\n",
    "    \n",
    "    max_r2_train = inner_res[[\"split0_train_r2\", \"split1_train_r2\", \"split2_train_r2\", \"split3_train_r2\"]].max()\n",
    "    mean_r2_train.append(np.mean(max_r2_train))\n",
    "        \n",
    "    max_neg_MSE_train = inner_res[[\"split0_train_neg_mean_squared_error\", \"split1_train_neg_mean_squared_error\", \"split2_train_neg_mean_squared_error\", \"split3_train_neg_mean_squared_error\"]].max()\n",
    "    mean_neg_MSE_train.append(np.mean(max_neg_MSE_train))\n",
    "\n",
    "    max_neg_MSE_test = inner_res[[\"split0_test_neg_mean_squared_error\", \"split1_test_neg_mean_squared_error\", \"split2_test_neg_mean_squared_error\", \"split3_test_neg_mean_squared_error\"]].max()\n",
    "    mean_neg_MSE_test.append(np.mean(max_neg_MSE_test))\n",
    "    \n",
    "    max_neg_mean_absolute_error_train = inner_res[[\"split0_train_neg_mean_absolute_error\", \"split1_train_neg_mean_absolute_error\", \"split2_train_neg_mean_absolute_error\", \"split3_train_neg_mean_absolute_error\"]].max()\n",
    "    mean_neg_mean_absolute_error_train.append(np.mean(max_neg_mean_absolute_error_train))\n",
    "\n",
    "    max_neg_mean_absolute_error_test = inner_res[[\"split0_test_neg_mean_absolute_error\", \"split1_test_neg_mean_absolute_error\", \"split2_test_neg_mean_absolute_error\", \"split3_test_neg_mean_absolute_error\"]].max()\n",
    "    mean_neg_mean_absolute_error_test.append(np.mean(max_neg_mean_absolute_error_test))\n",
    "\n",
    "statistics = pd.DataFrame([np.mean(mean_r2_train), np.mean(mean_r2_test),\n",
    "              abs(np.mean(mean_neg_mean_absolute_error_train)),\n",
    "              abs(np.mean(mean_neg_mean_absolute_error_test)),\n",
    "              np.sqrt(abs(abs(np.mean(mean_neg_MSE_train)))),\n",
    "              np.sqrt(abs(abs(np.mean(mean_neg_MSE_test))))])\n",
    "              \n",
    "statistics.to_csv(\"statistics_XGB_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ce77b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0\n",
      "0  1.000000\n",
      "1  0.463856\n",
      "2  0.000415\n",
      "3  7.239659\n",
      "4  0.000780\n",
      "5  9.724173\n"
     ]
    }
   ],
   "source": [
    "print(statistics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
